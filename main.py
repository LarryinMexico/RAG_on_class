import os
import json
import pickle
import gradio as gr
import numpy as np
import requests
import re  # æ·»åŠ  re æ¨¡çµ„å°å…¥
from typing import List, Dict, Tuple
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv
import warnings
import uuid
import shutil
import atexit
import time
warnings.filterwarnings('ignore')

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class RAGSystem:
    def __init__(self, model_name: str = 'all-mpnet-base-v2'):
        """åˆå§‹åŒ– RAG ç³»çµ±"""
        self.model = SentenceTransformer(model_name)
        self.course_data = []
        self.embeddings = []
        self.api_key = os.getenv('GROQ_API_KEY')
        self.data_dir = "uploads"
        self.last_api_call = 0  # è¨˜éŒ„ä¸Šæ¬¡ API å‘¼å«æ™‚é–“
        os.makedirs(self.data_dir, exist_ok=True)
        self.current_session = None
        # å•Ÿå‹•æ™‚ä¸è‡ªå‹•è¼‰å…¥è³‡æ–™
        # self.load_data()
    
    def split_text_into_chunks(self, text: str, chunk_size: int = 150) -> List[str]:
        """å°‡æ–‡æœ¬åˆ†å‰²æˆæŒ‡å®šå¤§å°çš„æ®µè½"""
        words = text.split()
        chunks = []
        current_chunk = []
        current_length = 0
        
        for word in words:
            if current_length + len(word) + 1 <= chunk_size:
                current_chunk.append(word)
                current_length += len(word) + 1
            else:
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                current_chunk = [word]
                current_length = len(word)
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
    
    def prepare_course_data(self, course_texts: List[str]) -> None:
        """æº–å‚™èª²ç¨‹è³‡æ–™ä¸¦ç”ŸæˆåµŒå…¥å‘é‡"""
        print("æ­£åœ¨è™•ç†èª²ç¨‹è³‡æ–™...")
        all_chunks = []
        for text in course_texts:
            chunks = self.split_text_into_chunks(text)
            all_chunks.extend(chunks)
        self.course_data = all_chunks
        print("æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...")
        self.embeddings = self.model.encode(self.course_data)
        # æ–°å¢å”¯ä¸€è³‡æ–™å¤¾
        session_id = str(uuid.uuid4())
        session_path = os.path.join(self.data_dir, session_id)
        os.makedirs(session_path, exist_ok=True)
        self.current_session = session_path
        # å­˜æª”
        with open(os.path.join(session_path, 'course_data.json'), 'w', encoding='utf-8') as f:
            json.dump({'course_data': self.course_data}, f, ensure_ascii=False, indent=2)
        with open(os.path.join(session_path, 'embeddings.pkl'), 'wb') as f:
            pickle.dump(self.embeddings, f)
        print(f"å·²è™•ç† {len(self.course_data)} å€‹æ®µè½")
    
    def clear_all_data(self):
        shutil.rmtree(self.data_dir)
        os.makedirs(self.data_dir, exist_ok=True)
        self.current_session = None
        self.course_data = []
        self.embeddings = []
    
    def load_data(self) -> None:
        # ä¸å†æ–¼å•Ÿå‹•æ™‚è‡ªå‹•è¼‰å…¥
        pass
    
    def retrieve_relevant_chunks(self, query: str, k: int = 3) -> List[Tuple[str, float]]:
        """æª¢ç´¢ç›¸é—œæ®µè½"""
        if not self.course_data:
            return []
        
        # å°æŸ¥è©¢é€²è¡Œç·¨ç¢¼
        query_embedding = self.model.encode([query])
        
        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        
        # ç²å–å‰ k å€‹æœ€ç›¸ä¼¼çš„æ®µè½
        top_indices = np.argsort(similarities)[::-1][:k]
        
        relevant_chunks = []
        for idx in top_indices:
            if similarities[idx] > 0.1:  # è¨­å®šæœ€ä½ç›¸ä¼¼åº¦é–¾å€¼
                relevant_chunks.append((self.course_data[idx], similarities[idx]))
        
        return relevant_chunks
    
    def call_groq_api(self, messages, max_retries=3, initial_wait=30):
        """è™•ç† Groq API å‘¼å«ï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶"""
        current_time = time.time()
        # ç¢ºä¿èˆ‡ä¸Šæ¬¡ API å‘¼å«é–“éš”è‡³å°‘ 1 ç§’
        time_since_last_call = current_time - self.last_api_call
        if time_since_last_call < 1:
            time.sleep(1 - time_since_last_call)

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            "model": "llama3-70b-8192",
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 3000
        }

        for attempt in range(max_retries):
            try:
                response = requests.post(
                    'https://api.groq.com/openai/v1/chat/completions',
                    headers=headers,
                    json=data,
                    timeout=30
                )
                self.last_api_call = time.time()

                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:  # Rate limit error
                    wait_time = initial_wait * (attempt + 1)  # é€æ¬¡å¢åŠ ç­‰å¾…æ™‚é–“
                    print(f"é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"API éŒ¯èª¤ï¼š{response.status_code} - {response.text}")
                    return None

            except Exception as e:
                print(f"API å‘¼å«å‡ºéŒ¯ï¼š{str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(initial_wait)
                    continue
                return None

        return None

    def generate_questions(self, num_questions=5):
        """ç”Ÿæˆé¡Œç›®çš„ä¸»è¦å‡½æ•¸"""
        print("é–‹å§‹ç”Ÿæˆé¡Œç›®...")
        
        # æª¢æŸ¥èª²ç¨‹è³‡æ–™æ˜¯å¦å­˜åœ¨
        if not self.course_data:
            print("éŒ¯èª¤ï¼šæ²’æœ‰èª²ç¨‹è³‡æ–™å¯ç”¨")
            return []
        
        print(f"èª²ç¨‹è³‡æ–™æ®µè½æ•¸: {len(self.course_data)}")
        
        # ä½¿ç”¨éƒ¨åˆ†èª²ç¨‹å…§å®¹ä¾†é¿å…è¶…é token é™åˆ¶
        max_context_length = 2000  # å­—å…ƒæ•¸é™åˆ¶
        context = ""
        for chunk in self.course_data:
            if len(context) + len(chunk) + 1 <= max_context_length:
                context += chunk + "\n"
            else:
                break
        
        print(f"ä½¿ç”¨çš„ä¸Šä¸‹æ–‡é•·åº¦: {len(context)} å­—å…ƒ")
        
        # æ›´æ˜ç¢ºçš„æç¤ºè©ï¼Œå¼·èª¿æ ¼å¼è¦æ±‚
        prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹èª²ç¨‹å…§å®¹ï¼Œç”Ÿæˆ{num_questions}é¡Œç¹é«”ä¸­æ–‡å–®é¸é¡Œã€‚æ¯é¡Œå¿…é ˆåš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š

é¡Œç›®1ï¼š[é¡Œç›®å…§å®¹]
A. [é¸é …Aå…§å®¹]
B. [é¸é …Bå…§å®¹]
C. [é¸é …Cå…§å®¹]
D. [é¸é …Då…§å®¹]
ç­”æ¡ˆï¼š[Aæˆ–Bæˆ–Cæˆ–D]

é¡Œç›®2ï¼š[é¡Œç›®å…§å®¹]
...ä»¥æ­¤é¡æ¨

æ³¨æ„äº‹é …ï¼š
1. æ¯é¡Œå¿…é ˆä»¥ã€Œé¡Œç›®Xï¼šã€é–‹é ­ï¼ŒXç‚ºé¡Œè™Ÿ
2. é¸é …å¿…é ˆç‚ºAã€Bã€Cã€Då››å€‹ï¼Œæ¯å€‹é¸é …å–®ç¨ä¸€è¡Œ
3. ç­”æ¡ˆå¿…é ˆæ¨™æ˜ç‚ºã€Œç­”æ¡ˆï¼šXã€ï¼ŒXç‚ºAã€Bã€Cã€Då…¶ä¸­ä¹‹ä¸€
4. è«‹å‹¿ä½¿ç”¨ã€Œä»¥ä¸Šçš†æ˜¯ã€ã€ã€Œä»¥ä¸Šçš†éã€ç­‰æ¨¡ç³Šé¸é …
5. é¡Œç›®å¿…é ˆèˆ‡æä¾›çš„èª²ç¨‹å…§å®¹ç›´æ¥ç›¸é—œ
6. æ‰€æœ‰å…§å®¹å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡

èª²ç¨‹å…§å®¹ï¼š
{context}"""

        print("å‘¼å« API ç”Ÿæˆé¡Œç›®...")
        result = self.call_groq_api([{"role": "user", "content": prompt}])
        if result:
            print("æˆåŠŸç²å– API å›æ‡‰")
            full_content = result['choices'][0]['message']['content'].strip()
            # è¼¸å‡ºå‰50å€‹å­—å…ƒï¼Œå¹«åŠ©èª¿è©¦
            print(f"APIå›æ‡‰é–‹é ­: {full_content[:100]}...")
            
            # å˜—è©¦ç›´æ¥è™•ç†æ•¸å­—é¡Œè™Ÿçš„æƒ…æ³
            if "é¡Œç›®1ï¼š" not in full_content and "é¡Œç›®1:" not in full_content:
                print("è™•ç†æ›¿ä»£æ ¼å¼...")
                modified_content = ""
                # å°‹æ‰¾æ•¸å­—é–‹é ­çš„è¡Œ
                lines = full_content.split('\n')
                for i, line in enumerate(lines):
                    # å¦‚æœè¡Œä»¥æ•¸å­—+é»/é “è™Ÿé–‹é ­ï¼Œå°‡å…¶è½‰æ›ç‚ºã€Œé¡Œç›®Xï¼šã€æ ¼å¼
                    if re.match(r'^\d+[\.\ã€\:]', line):
                        num = re.match(r'^\d+', line).group(0)
                        rest = re.sub(r'^\d+[\.\ã€\:\s]+', '', line)
                        modified_content += f"é¡Œç›®{num}ï¼š{rest}\n"
                    else:
                        modified_content += line + "\n"
                full_content = modified_content
            
            qa_list = self.parse_questions_and_answers(full_content)
            print(f"è§£æå‡º {len(qa_list)} é¡Œ")
            return qa_list
        else:
            print("API å›æ‡‰å¤±æ•—æˆ–ç‚ºç©º")
            return []

    def parse_questions_and_answers(self, full_content):
        """å°‡ LLM å›å‚³çš„é¡Œç›®èˆ‡ç­”æ¡ˆåˆ†é–‹ï¼Œå›å‚³ [(é¡Œç›®, [A,B,C,D], ç­”æ¡ˆ)]"""
        import re
        print("é–‹å§‹è§£æé¡Œç›®èˆ‡ç­”æ¡ˆ...")
        print(f"åŸå§‹å…§å®¹é•·åº¦: {len(full_content)} å­—å…ƒ")
        
        qa_list = []
        
        # å˜—è©¦å¤šç¨®å¯èƒ½çš„é¡Œç›®æ ¼å¼
        patterns = [
            # æ¨™æº–ã€Œé¡Œç›®Xï¼šã€æ ¼å¼
            r'é¡Œç›®\d+[ï¼š:](.*?)(?=é¡Œç›®\d+[ï¼š:]|$)',
            # æ•¸å­—+é»/é “è™Ÿæ ¼å¼
            r'\d+[\.\ã€](.*?)(?=\d+[\.\ã€]|$)',
            # ç›´æ¥ã€Œé¡Œç›®ï¼šã€æ ¼å¼
            r'é¡Œç›®[ï¼š:](.*?)(?=é¡Œç›®[ï¼š:]|$)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, full_content, re.DOTALL)
            if matches:
                print(f"ä½¿ç”¨æ¨¡å¼ '{pattern}' æ‰¾åˆ° {len(matches)} å€‹åŒ¹é…")
                break
        
        if not matches:
            print("ç„¡æ³•è­˜åˆ¥ä»»ä½•é¡Œç›®æ ¼å¼ï¼Œå˜—è©¦æŒ‰è¡Œåˆ†æ...")
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•é¡Œç›®æ ¼å¼ï¼Œå˜—è©¦ç›´æ¥æŒ‰è¡Œåˆ†æ
            lines = full_content.split('\n')
            current_question = None
            current_options = []
            current_answer = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°é¡Œç›®
                q_match = re.match(r'^\d+[\.\ã€\:]?\s*(.*)', line)
                if q_match and not re.match(r'^[A-D][\.\ã€\:]', line):
                    # ä¿å­˜ä¹‹å‰çš„é¡Œç›®
                    if current_question and current_options and current_answer:
                        qa_list.append((current_question, current_options, current_answer))
                    
                    # é–‹å§‹æ–°é¡Œç›®
                    current_question = q_match.group(1)
                    current_options = []
                    current_answer = None
                    continue
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯é¸é …
                opt_match = re.match(r'^([A-D])[\.\ã€\:]?\s*(.*)', line)
                if opt_match:
                    current_options.append(f"{opt_match.group(1)}. {opt_match.group(2)}")
                    continue
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯ç­”æ¡ˆ
                ans_match = re.match(r'^ç­”æ¡ˆ[\.\ã€\:\s]*([A-D])', line)
                if ans_match:
                    current_answer = ans_match.group(1)
                    continue
                
                # å¦‚æœéƒ½ä¸æ˜¯ï¼Œå¯èƒ½æ˜¯é¡Œç›®çš„ä¸€éƒ¨åˆ†
                if current_question:
                    current_question += " " + line
            
            # ä¿å­˜æœ€å¾Œä¸€é¡Œ
            if current_question and current_options and current_answer:
                qa_list.append((current_question, current_options, current_answer))
            
            return qa_list
        
        # è™•ç†æ‰¾åˆ°çš„é¡Œç›®å€å¡Š
        for block in matches:
            try:
                # å–é¸é … (æ”¯æ´å¤šç¨®æ ¼å¼)
                options = re.findall(r'([A-D])[\.\ã€\:\s]+(.*?)(?=[A-D][\.\ã€\:]|ç­”æ¡ˆ|$)', block, re.DOTALL)
                if not options:
                    print(f"è­¦å‘Š: åœ¨å€å¡Šä¸­æœªæ‰¾åˆ°é¸é …")
                    continue
                
                # æ ¼å¼åŒ–é¸é …
                formatted_options = [f"{opt[0]}. {opt[1].strip()}" for opt in options]
                
                # å–é¡Œå¹¹ - å¾å€å¡Šé–‹å§‹åˆ°ç¬¬ä¸€å€‹é¸é …ä¹‹å‰
                first_option_match = re.search(r'[A-D][\.\ã€\:\s]+', block)
                if first_option_match:
                    question_end = first_option_match.start()
                    question = block[:question_end].strip()
                else:
                    question = block.strip()
                
                # å¦‚æœé¡Œå¹¹ç‚ºç©ºï¼Œä½¿ç”¨å€å¡Šçš„å‰50å€‹å­—å…ƒ
                if not question:
                    question = block[:50].strip() + "..."
                
                # å–ç­”æ¡ˆ (æ”¯æ´å¤šç¨®æ ¼å¼)
                ans_match = re.search(r'ç­”æ¡ˆ[\.\ã€\:\s]*([A-D])', block)
                answer = ans_match.group(1) if ans_match else ''
                
                if not answer and len(formatted_options) > 0:
                    # å¦‚æœæ²’æ‰¾åˆ°ç­”æ¡ˆä½†æœ‰é¸é …ï¼Œé»˜èªä½¿ç”¨A
                    print("è­¦å‘Š: æœªæ‰¾åˆ°ç­”æ¡ˆï¼Œé»˜èªä½¿ç”¨A")
                    answer = 'A'
                
                print(f"æˆåŠŸè§£æé¡Œç›®: '{question[:20]}...' é¸é …æ•¸: {len(formatted_options)} ç­”æ¡ˆ: {answer}")
                qa_list.append((question, formatted_options, answer))
                
            except Exception as e:
                print(f"è§£æå€å¡Šæ™‚å‡ºéŒ¯: {str(e)}")
                continue
        
        print(f"æœ€çµ‚è§£æå‡º {len(qa_list)} é¡Œå®Œæ•´å•ç­”")
        return qa_list

    def get_standard_answers(self, qa_list, idx):
        # å›å‚³ç¬¬ idx é¡Œçš„æ¨™æº–ç­”æ¡ˆ
        if not qa_list or idx >= len(qa_list):
            return "ç„¡æ³•å–å¾—ç­”æ¡ˆ"
        return f"æ¨™æº–ç­”æ¡ˆï¼š{qa_list[idx][2]}"
    
    def analyze_user_answers(self, user_answers, num_questions=5):
        if not self.course_data:
            return "è«‹å…ˆä¸Šå‚³èª²ç¨‹è³‡æ–™"
        context = "\n".join(self.course_data[:10])
        prompt = f"ä»¥ä¸‹æ˜¯å­¸ç”Ÿçš„ä½œç­”çµæœï¼Œè«‹æ ¹æ“šæ¨™æº–ç­”æ¡ˆé€²è¡Œæ‰¹æ”¹ï¼Œä¸¦çµ¦äºˆæ¯é¡Œç°¡çŸ­è¬›è©•èˆ‡ç¸½çµå»ºè­°ã€‚\n\nèª²ç¨‹å…§å®¹ï¼š\n{context}\n\nå­¸ç”Ÿä½œç­”ï¼š\n{user_answers}\n\nè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            data = {
                "model": "llama3-70b-8192",
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 3000
            }
            response = requests.post(
                'https://api.groq.com/openai/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content'].strip()
            else:
                return f"API éŒ¯èª¤ï¼š{response.status_code} - {response.text}"
        except Exception as e:
            return f"åˆ†æä½œç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
    
    def answer_query(self, query: str) -> Tuple[str, str]:
        """å›ç­”ç”¨æˆ¶å•é¡Œçš„ä¸»è¦å‡½æ•¸ï¼Œè¿”å›ç­”æ¡ˆå’Œç›¸é—œæ®µè½"""
        if not query.strip():
            return "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ", ""
        
        relevant_chunks = self.retrieve_relevant_chunks(query, k=3)
        
        is_course_related = False
        if self.course_data:
            query_embedding = self.model.encode([query])
            max_similarity = max(cosine_similarity(query_embedding, self.embeddings)[0])
            is_course_related = max_similarity > 0.3

        if is_course_related and relevant_chunks:
            context = "\n\n".join([chunk for chunk, score in relevant_chunks])
            source_info = "\n\nç›¸é—œæ®µè½ï¼š\n" + "\n---\n".join([f"ç›¸ä¼¼åº¦ {score:.2f}ï¼š{chunk}" for chunk, score in relevant_chunks])
            prompt = f"""è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ä»¥ä¸‹å•é¡Œã€‚æ ¹æ“šä¸Šä¸‹æ–‡å›ç­”ï¼Œå¦‚æœä¸Šä¸‹æ–‡è³‡è¨Šä¸è¶³ï¼Œä½ å¯ä»¥æ ¹æ“šä½ çš„çŸ¥è­˜è£œå……å›ç­”ï¼Œä½†è«‹æ˜ç¢ºæŒ‡å‡ºå“ªäº›æ˜¯ä¾†è‡ªä¸Šä¸‹æ–‡ï¼Œå“ªäº›æ˜¯ä½ çš„è£œå……èªªæ˜ã€‚è«‹ç¢ºä¿å›ç­”å®Œå…¨ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•è‹±æ–‡ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

å•é¡Œï¼š{query}

è«‹æä¾›è©³ç´°çš„ç¹é«”ä¸­æ–‡å›ç­”ï¼š"""
        else:
            prompt = f"""è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ä»¥ä¸‹å•é¡Œï¼Œæä¾›è©³ç´°ä¸”æœ‰å¹«åŠ©çš„è³‡è¨Šã€‚è«‹ç¢ºä¿å›ç­”å®Œå…¨ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•è‹±æ–‡ã€‚

å•é¡Œï¼š{query}

è«‹æä¾›è©³ç´°çš„ç¹é«”ä¸­æ–‡å›ç­”ï¼š"""
            source_info = "æ­¤å›ç­”ä¾†è‡ª AI çš„ä¸€èˆ¬çŸ¥è­˜ï¼Œæœªåƒè€ƒä¸Šå‚³çš„èª²ç¨‹å…§å®¹ã€‚"

        result = self.call_groq_api([{"role": "user", "content": prompt}])
        if result:
            answer = result['choices'][0]['message']['content'].strip()
            return answer, source_info
        return "æŠ±æ­‰ï¼Œæš«æ™‚ç„¡æ³•ç”Ÿæˆå›ç­”ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", source_info

# åˆå§‹åŒ– RAG ç³»çµ±
rag_system = RAGSystem()

def upload_and_process_files(files):
    """è™•ç†ä¸Šå‚³çš„æ–‡ä»¶"""
    if not files:
        return "è«‹é¸æ“‡è¦ä¸Šå‚³çš„æ–‡ä»¶"
    course_texts = []
    for file in files:
        try:
            if hasattr(file, 'read') and callable(file.read):
                # gradio 3.x/4.x ä¸Šå‚³æ™‚æ˜¯ file-like object
                file.seek(0)
                content = file.read()
                if isinstance(content, bytes):
                    content = content.decode('utf-8')
            elif hasattr(file, 'name'):
                # gradio æŸäº›æƒ…å¢ƒæ˜¯ NamedString
                with open(file.name, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:
                return f"ç„¡æ³•è­˜åˆ¥çš„æª”æ¡ˆå‹æ…‹"
            course_texts.append(content)
        except Exception as e:
            return f"è®€å–æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
    # æº–å‚™èª²ç¨‹è³‡æ–™
    rag_system.prepare_course_data(course_texts)
    return f"æˆåŠŸè™•ç† {len(files)} å€‹æ–‡ä»¶ï¼Œå…± {len(rag_system.course_data)} å€‹æ®µè½"

def answer_question(question):
    """å›ç­”å•é¡Œçš„ä»‹é¢å‡½æ•¸"""
    answer, source_info = rag_system.answer_query(question)
    return answer, source_info

def create_interface():
    with gr.Blocks(title="RAG ON CLASS - èª²ç¨‹å•ç­”ç³»çµ±") as interface:
        gr.Markdown("# ğŸ“š RAG ON CLASS - èª²ç¨‹å•ç­”ç³»çµ±")
        gr.Markdown("ä¸Šå‚³æ‚¨çš„èª²ç¨‹è³‡æ–™ï¼Œç„¶å¾Œè©¢å•ä»»ä½•ç›¸é—œå•é¡Œï¼")
        with gr.Tab("ğŸ“ è³‡æ–™ä¸Šå‚³"):
            file_upload = gr.File(
                label="ä¸Šå‚³èª²ç¨‹æ–‡ä»¶ (æ”¯æ´ .txt æ–‡ä»¶)",
                file_count="multiple",
                file_types=[".txt"]
            )
            upload_btn = gr.Button("è™•ç†ä¸Šå‚³çš„æ–‡ä»¶", variant="primary")
            upload_status = gr.Textbox(label="è™•ç†ç‹€æ…‹", interactive=False)
            upload_btn.click(
                upload_and_process_files,
                inputs=[file_upload],
                outputs=[upload_status]
            )
        with gr.Tab("â“ ä½œç­”ç³»çµ±"):
            question_input = gr.Textbox(
                label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
                lines=2
            )
            submit_btn = gr.Button("æäº¤å•é¡Œ", variant="primary")
            answer_output = gr.Textbox(
                label="å›ç­”",
                lines=15,
                interactive=False
            )
            source_output = gr.Textbox(
                label="åƒè€ƒä¾†æº",
                lines=10,
                interactive=False
            )
            submit_btn.click(
                answer_question,
                inputs=[question_input],
                outputs=[answer_output, source_output]
            )
            question_input.submit(
                answer_question,
                inputs=[question_input],
                outputs=[answer_output, source_output]
            )
        with gr.Tab("ğŸ“ ä¸€éµç”Ÿæˆé¡Œç›®"):
            questions_state = gr.State([])
            with gr.Row():
                with gr.Column(scale=1):
                    generate_btn = gr.Button("ä¸€éµç”Ÿæˆé¡Œç›®", variant="primary")
                    questions_output = gr.Textbox(
                        label="ç”Ÿæˆçš„é¡Œç›®",
                        lines=15,
                        interactive=False
                    )
                with gr.Column(scale=1):
                    show_answer_btn = gr.Button("é¡¯ç¤ºæ¨™æº–ç­”æ¡ˆ", variant="secondary")
                    answers_output = gr.Textbox(
                        label="æ¨™æº–ç­”æ¡ˆ",
                        lines=15,
                        interactive=False
                    )

            def generate_and_show():
                print("è§¸ç™¼ç”Ÿæˆé¡Œç›®æŒ‰éˆ•...")
                qa_list = rag_system.generate_questions()
                if not qa_list:
                    print("æœªèƒ½ç”Ÿæˆé¡Œç›®")
                    # å˜—è©¦ä½¿ç”¨æ›´ç°¡å–®çš„æ–¹æ³•ç”Ÿæˆé¡Œç›®
                    print("å˜—è©¦ä½¿ç”¨å‚™ç”¨æ–¹æ³•ç”Ÿæˆé¡Œç›®...")
                    # å‰µå»ºä¸€äº›ç¤ºä¾‹é¡Œç›®
                    if rag_system.course_data:
                        qa_list = [
                            ("æ ¹æ“šèª²ç¨‹å…§å®¹ï¼Œé€™æ˜¯ä¸€å€‹ç¤ºä¾‹é¡Œç›®ï¼Ÿ", ["A. ç¬¬ä¸€å€‹é¸é …", "B. ç¬¬äºŒå€‹é¸é …", "C. ç¬¬ä¸‰å€‹é¸é …", "D. ç¬¬å››å€‹é¸é …"], "A"),
                            ("é€™æ˜¯ç¬¬äºŒå€‹ç¤ºä¾‹é¡Œç›®ï¼Ÿ", ["A. é¸é …A", "B. é¸é …B", "C. é¸é …C", "D. é¸é …D"], "B")
                        ]
                        print("å·²å‰µå»ºç¤ºä¾‹é¡Œç›®")
                
                # æ ¼å¼åŒ–é¡Œç›®é¡¯ç¤º
                questions_text = ""
                if qa_list:
                    print(f"æˆåŠŸç”Ÿæˆ {len(qa_list)} é¡Œ")
                    for idx, (q, opts, _) in enumerate(qa_list, 1):
                        questions_text += f"ç¬¬{idx}é¡Œï¼š{q}\n"
                        for opt in opts:
                            questions_text += f"{opt}\n"
                        questions_text += "\n"
                else:
                    questions_text = "ç„¡æ³•ç”¢ç”Ÿé¡Œç›®ï¼Œè«‹ç¢ºèªå·²ä¸Šå‚³èª²ç¨‹è³‡æ–™"
                
                return qa_list, questions_text

            def show_answers(qa_list):
                print(f"é¡¯ç¤ºç­”æ¡ˆæŒ‰éˆ•è¢«é»æ“Šï¼Œqa_listé•·åº¦: {len(qa_list) if qa_list else 0}")
                if not qa_list:
                    return "è«‹å…ˆç”Ÿæˆé¡Œç›®"
                
                # æ ¼å¼åŒ–ç­”æ¡ˆé¡¯ç¤º
                answers_text = ""
                for idx, (_, _, ans) in enumerate(qa_list, 1):
                    answers_text += f"ç¬¬{idx}é¡Œç­”æ¡ˆï¼š{ans}\n"
                
                return answers_text

            # è¨­ç½®æŒ‰éˆ•äº‹ä»¶
            generate_btn.click(
                generate_and_show,
                inputs=[],
                outputs=[questions_state, questions_output]
            )

            show_answer_btn.click(
                show_answers,
                inputs=[questions_state],
                outputs=[answers_output]
            )
        with gr.Tab("â„¹ï¸ ç³»çµ±è³‡è¨Š"):
            gr.Markdown("""
            ## ä½¿ç”¨èªªæ˜
            1. **ä¸Šå‚³è³‡æ–™**ï¼šåœ¨ã€Œè³‡æ–™ä¸Šå‚³ã€æ¨™ç±¤ä¸­ä¸Šå‚³æ‚¨çš„èª²ç¨‹æ–‡ä»¶ï¼ˆ.txt æ ¼å¼ï¼‰
            2. **è™•ç†è³‡æ–™**ï¼šé»æ“Šã€Œè™•ç†ä¸Šå‚³çš„æ–‡ä»¶ã€æŒ‰éˆ•ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†å‰²æ–‡æœ¬ä¸¦ç”ŸæˆåµŒå…¥å‘é‡
            3. **æå•**ï¼šåœ¨ã€Œä½œç­”ç³»çµ±ã€æ¨™ç±¤ä¸­è¼¸å…¥æ‚¨çš„å•é¡Œ
            4. **ç²å¾—å›ç­”**ï¼šç³»çµ±æœƒæª¢ç´¢ç›¸é—œå…§å®¹ä¸¦ç”Ÿæˆå›ç­”
            5. **ä¸€éµç”Ÿæˆé¡Œç›®/ç­”æ¡ˆ**ï¼šåœ¨ã€Œä¸€éµç”Ÿæˆé¡Œç›®ã€æ¨™ç±¤é»æ“ŠæŒ‰éˆ•è‡ªå‹•ç”Ÿæˆé¡Œç›®èˆ‡æ¨™æº–ç­”æ¡ˆ
            ## ç³»çµ±ç‰¹è‰²
            - ğŸ” ä½¿ç”¨ Sentence-BERT é€²è¡Œèªç¾©æª¢ç´¢
            - ğŸ§  æ•´åˆ Groq API ç”Ÿæˆæ™ºèƒ½å›ç­”èˆ‡è‡ªå‹•å‡ºé¡Œ
            - ğŸ“Š é¤˜å¼¦ç›¸ä¼¼åº¦åŒ¹é…æœ€ç›¸é—œå…§å®¹
            - ğŸ’¾ æœ¬åœ°å„²å­˜è™•ç†å¾Œçš„è³‡æ–™
            - ğŸŒ å‹å¥½çš„ç¶²é ä»‹é¢
            ## æ³¨æ„äº‹é …
            - è«‹ç¢ºä¿åœ¨ .env æ–‡ä»¶ä¸­è¨­å®š GROQ_API_KEY
            - æ”¯æ´çš„æ–‡ä»¶æ ¼å¼ï¼š.txt
            - ç³»çµ±æœƒå°‡æ–‡æœ¬åˆ†å‰²æˆç´„150å­—çš„æ®µè½é€²è¡Œè™•ç†
            """)
    return interface

# ç¨‹å¼çµæŸæ™‚è‡ªå‹•æ¸…ç©º uploads
atexit.register(rag_system.clear_all_data)

if __name__ == "__main__":
    # å‰µå»ºä¸¦å•Ÿå‹•ä»‹é¢
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )